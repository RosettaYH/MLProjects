{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "indirect-conditioning",
   "metadata": {},
   "source": [
    "# Book Recommender System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complete-literacy",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-blast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applicable-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pregnant-chemical",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['description'] = df['Desc']\n",
    "df = df.drop(['Desc'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-console",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = df['description'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaging-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "toxic-cheat",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "municipal-brazil",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "spanish-complexity",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(df['genre'], label='Count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-manchester",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.histplot(df['word_count'], label='Count', bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crude-advocate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_text_ngrams(corpus, n, g):\n",
    "    tf = TfidfVectorizer(ngram_range=(g, g), stop_words='english', lowercase = False)\n",
    "    bag_of_words = tf.fit_transform(corpus)\n",
    "    sum_words = bag_of_words.sum(axis=0) \n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in tf.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:n]\n",
    "\n",
    "def show_ngrams(n, title):\n",
    "    plt.figure(figsize=(16,9))\n",
    "    most_common = get_top_text_ngrams(df['description'], 20, n)\n",
    "    most_common = dict(most_common)\n",
    "    plt.title(title)\n",
    "    sns.barplot(x=list(most_common.values()), y=list(most_common.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ordinary-darkness",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_ngrams(1, 'Unigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-invention",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_ngrams(2, 'Bigram')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-profession",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_ngrams(3, 'Trigram')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chief-image",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mature-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    text = text.split()\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in text if not w in stops]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "def remove_punctuation(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    text = tokenizer.tokenize(text)\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "def remove_html(text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "def clean_text(text):\n",
    "    text = \"\".join(i for i in text if ord(i)<128)\n",
    "    text = re.sub('<.*?>', '', text)\n",
    "    text = text.lower()\n",
    "    text = remove_stopwords(text)\n",
    "    text = remove_punctuation(text)\n",
    "    return text\n",
    "\n",
    "df['description'] = df['description'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-spank",
   "metadata": {},
   "source": [
    "### Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "powered-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), min_df = 1, stop_words='english')\n",
    "tfidf_matrix = tf.fit_transform(df['description'])\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "secure-example",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title):\n",
    "    idx = df.loc[df['title'] == title].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:]\n",
    "    indices = [i[0] for i in sim_scores]\n",
    "    return df.loc[indices][['title', 'author', 'description', 'image_link']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "female-moore",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(df):\n",
    "    df = df.head()\n",
    "    fig, axs = plt.subplots(1, 5, figsize=(20, 15))\n",
    "    for ax, (_, row) in zip(axs, df.iterrows()):\n",
    "        response = requests.get(row.image_link)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        ax.imshow(img, interpolation='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "rec = get_recommendations(\"Steve Jobs\")\n",
    "rec.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "downtown-tanzania",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_images(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Inspiration\n",
    "1. https://www.kdnuggets.com/2020/07/building-content-based-book-recommendation-engine.html\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
