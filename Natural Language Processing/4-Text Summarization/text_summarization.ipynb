{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hidden-damages",
   "metadata": {},
   "source": [
    "# Text Summarization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessory-gilbert",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "purple-ethnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "# from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from attention import AttentionLayer\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conservative-aruba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Reviews.csv', nrows=100000)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "romantic-republican",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "economic-application",
   "metadata": {},
   "source": [
    "### Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "portuguese-rubber",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['Text'], inplace=True)\n",
    "df.dropna(axis=0, inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fluid-hacker",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english')) \n",
    "    tokens = [w for w in text.split() if not w in stop_words]\n",
    "    final_text = []\n",
    "    for i in tokens:\n",
    "        if len(i) >= 3:\n",
    "            final_text.append(i)  \n",
    "    return (\" \".join(final_text)).strip()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = BeautifulSoup(text, \"lxml\").text\n",
    "    text = re.sub(r'\\([^)]*\\)', '', text)\n",
    "    text = re.sub('\"', '', text)\n",
    "    text = re.sub(r\"'s\\b\", '', text)\n",
    "    text = re.sub(\"[^a-zA-Z]\", ' ', text) \n",
    "    text = remove_stopwords(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-tunnel",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Text'] = df['Text'].apply(clean_text)\n",
    "df['Summary'] = df['Summary'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moving-target",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace('', np.nan, inplace=True)\n",
    "df.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stopped-leather",
   "metadata": {},
   "outputs": [],
   "source": [
    "len_df = pd.DataFrame(columns=['Text Length', 'Summary Length'])\n",
    "\n",
    "len_df['Text Length'] = df['Text'].apply(lambda x: len(str(x).split()))\n",
    "len_df['Summary Length'] = df['Summary'].apply(lambda x: len(str(x).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-forty",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12,6))\n",
    "sns.histplot(len_df['Text Length'], label='Count', bins=30, ax=ax1)\n",
    "sns.histplot(len_df['Summary Length'], label='Count', bins=30, ax=ax2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "detailed-exposure",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Summary'] = df['Summary'].apply(lambda x : '_START_ '+ x + ' _END_')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "english-preference",
   "metadata": {},
   "source": [
    "### Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-conversation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Text']\n",
    "y = df['Summary']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-theory",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_len = 80\n",
    "max_summary_len = 10\n",
    "padding_type='post'\n",
    "\n",
    "X_tokenizer = Tokenizer()\n",
    "X_tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = X_tokenizer.texts_to_sequences(X_train) \n",
    "X_train_padded = pad_sequences(X_train_seq,  maxlen=max_text_len, padding=padding_type) \n",
    "\n",
    "X_test_seq = X_tokenizer.texts_to_sequences(X_test)\n",
    "X_test_padded = pad_sequences(X_test_seq, maxlen=max_text_len, padding=padding_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "offensive-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tokenizer = Tokenizer()\n",
    "y_tokenizer.fit_on_texts(y_train)\n",
    "\n",
    "y_train_seq = y_tokenizer.texts_to_sequences(y_train) \n",
    "y_train_padded = pad_sequences(y_train_seq,  maxlen=max_summary_len, padding=padding_type) \n",
    "\n",
    "y_test_seq = y_tokenizer.texts_to_sequences(y_test)\n",
    "y_test_padded = pad_sequences(y_test_seq, maxlen=max_summary_len, padding=padding_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consistent-escape",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_padded\n",
    "y_train = y_train_padded\n",
    "X_test = X_test_padded\n",
    "y_test = y_test_padded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "national-circumstances",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-vietnam",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 500 \n",
    "x_voc_size = len(X_tokenizer.word_index) + 1\n",
    "y_voc_size = len(y_tokenizer.word_index) +1\n",
    "\n",
    "# Encoder \n",
    "encoder_inputs = Input(shape=(max_text_len,)) \n",
    "enc_emb = Embedding(x_voc_size, embedding_dim, trainable=True)(encoder_inputs) \n",
    "\n",
    "encoder_lstm1 = LSTM(embedding_dim, return_sequences=True, return_state=True) \n",
    "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
    "\n",
    "encoder_lstm2 = LSTM(embedding_dim, return_sequences=True, return_state=True) \n",
    "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
    "\n",
    "encoder_lstm3=LSTM(embedding_dim, return_state=True, return_sequences=True) \n",
    "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = Input(shape=(None,)) \n",
    "dec_emb_layer = Embedding(y_voc_size, embedding_dim,trainable=True) \n",
    "dec_emb = dec_emb_layer(decoder_inputs) \n",
    "\n",
    "decoder_lstm = LSTM(embedding_dim, return_sequences=True, return_state=True) \n",
    "decoder_outputs, decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb, initial_state=[state_h, state_c]) \n",
    "\n",
    "# Attention Layer\n",
    "attn_layer = AttentionLayer(name='attention_layer') \n",
    "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
    "\n",
    "# Concat\n",
    "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
    "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax')) \n",
    "decoder_outputs = decoder_dense(decoder_concat_input) \n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "skilled-flexibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lesbian-compact",
   "metadata": {},
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lasting-lighting",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(\n",
    "    [X_train, y_train[:,:-1]], y_train.reshape(y_train.shape[0], y_train.shape[1], 1)[:,1:], \n",
    "    validation_data=([X_test, y_test[:,:-1]], y_test.reshape(y_test.shape[0], y_test.shape[1], 1)[:,1:]),\n",
    "    epochs=30,\n",
    "    callbacks=[es],\n",
    "    batch_size=512)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "literary-rugby",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-spyware",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rotary-geology",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_index_word = X_tokenizer.index_word \n",
    "y_index_word = y_tokenizer.index_word \n",
    "y_word_index = y_tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprising-theorem",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])\n",
    "\n",
    "decoder_state_input_h = Input(shape=(embedding_dim,))\n",
    "decoder_state_input_c = Input(shape=(embedding_dim,))\n",
    "decoder_hidden_state_input = Input(shape=(max_text_len,embedding_dim))\n",
    "dec_emb2= dec_emb_layer(decoder_inputs)\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
    "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
    "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
    "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
    "decoder_model = Model([decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
    "                      [decoder_outputs2] + [state_h2, state_c2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-surgeon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq2summary(input_seq):\n",
    "    newString = ''\n",
    "    for i in input_seq:\n",
    "        if((i != 0 and i != y_word_index['start']) and i != y_word_index['end']):\n",
    "            newString = newString + y_index_word[i] + ' '\n",
    "    return newString\n",
    "\n",
    "def seq2text(input_seq):\n",
    "    newString = ''\n",
    "    for i in input_seq:\n",
    "        if(i != 0):\n",
    "            newString = newString + X_index_word[i] + ' '\n",
    "    return newString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serial-george",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
    "    target_seq = np.zeros((1,1))\n",
    "    target_seq[0, 0] = y_word_index['start']\n",
    "\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition: \n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
    "\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_token = y_index_word[sampled_token_index]\n",
    "        \n",
    "        if(sampled_token != 'end'):\n",
    "            decoded_sentence += ' ' + sampled_token\n",
    "        if (sampled_token == 'end'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
    "            stop_condition = True\n",
    "        target_seq = np.zeros((1,1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "        e_h, e_c = h, c\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-plain",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(\"Review:\", seq2text(X_test[i]))\n",
    "    print(\"Original summary:\", seq2summary(y_test[i]))\n",
    "    print(\"Predicted summary:\", decode_sequence(X_train[i].reshape(1, max_text_len)))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-bleeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Inspiration\n",
    "1. https://www.analyticsvidhya.com/blog/2019/06/comprehensive-guide-text-summarization-using-deep-learning-python/\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
